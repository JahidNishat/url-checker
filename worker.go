package main

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"os/signal"
	"sync"
	"sync/atomic"
	"syscall"
	"time"

	"github.com/redis/go-redis/v9"
)

var (
	httpClient     *http.Client
	processedCount int64
	stampede       *StampedePreventer
	cacheManager   *CacheManager
	err            error
	latencyTracker *LatencyTracker
)

type ResultsFlusher struct {
	rdb         *redis.Client
	resultsChan chan URLResult
	stopChan    chan struct{}
	wg          sync.WaitGroup
}

func NewResultsFlusher(rdb *redis.Client) *ResultsFlusher {
	f := &ResultsFlusher{
		rdb:         rdb,
		resultsChan: make(chan URLResult, 1000),
		stopChan:    make(chan struct{}),
	}
	f.wg.Add(1)
	go f.run()
	return f
}

func (f *ResultsFlusher) Add(ctx context.Context, result URLResult) {
	select {
	case f.resultsChan <- result:
	//Buffer successfully
	default:
		data, _ := json.Marshal(result)
		f.rdb.LPush(ctx, "results", data)
		log.Println("âš ï¸ Flusher channel full, direct write fallback")
	}
}

func (f *ResultsFlusher) run() {
	defer f.wg.Done()

	batch := make([]URLResult, 0, 500)
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	flush := func() {
		if len(batch) == 0 {
			return
		}

		args := make([]interface{}, len(batch))
		for i, result := range batch {
			data, _ := json.Marshal(result)
			args[i] = data
		}

		ctx := context.Background()
		if err := f.rdb.LPush(ctx, "results", args...).Err(); err != nil {
			log.Printf("âŒ Flush failed: %v\n", err)
		} else {
			log.Printf("ğŸ“¦ Flushed %d results to Redis\n", len(batch))
		}

		batch = batch[:0]
	}

	for {
		select {
		case result := <-f.resultsChan:
			batch = append(batch, result)

			if len(batch) >= 500 {
				flush()
			}

		case <-ticker.C:
			flush()
		case <-f.stopChan:
			flush()
			return
		}
	}
}

func (f *ResultsFlusher) Stop() {
	close(f.stopChan)
	f.wg.Wait()
	close(f.resultsChan)
}

func main() {
	//Load config
	config := LoadConfig()

	//Setup HTTP client
	httpClient = &http.Client{
		Timeout: time.Duration(config.HTTPTimeout) * time.Second,
		Transport: &http.Transport{
			MaxIdleConns:        100,
			MaxIdleConnsPerHost: 100,
			IdleConnTimeout:     90 * time.Second,
		},
	}

	workerID := fmt.Sprintf("worker-%d", os.Getpid())
	if len(os.Args) > 1 {
		// Last arg that's not a .go file
		for _, arg := range os.Args[1:] {
			if arg[len(arg)-3:] != ".go" {
				workerID = arg
			}
		}
	}

	rdb := NewRedisClient(config.RedisAddr)
	defer rdb.Close()

	flusher := NewResultsFlusher(rdb)
	defer flusher.Stop()

	stampede = NewStampedePreventer()

	cacheManager, err = NewCacheManager(1000, rdb, stampede)
	if err != nil {
		log.Printf("[%s] âŒ failed to create cache manager: %v\n", workerID, err)
		os.Exit(1)
	}

	latencyTracker = NewLatencyTracker()

	log.Printf("[%s] ğŸš€ Starting...\n", workerID)

	//Graceful Shutdown
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)

	go func() {
		<-sigChan
		log.Printf("\n[%s] ğŸ›‘ Shutting down gracefully...", workerID)
		log.Printf("[%s] ğŸ“Š Processed %d URLs in this session", workerID, atomic.LoadInt64(&processedCount))

		// âœ… NEW: Flush remaining batch before exit
		flusher.Stop()
		log.Printf("[%s] âœ… All batches flushed", workerID)

		// New: Print stats
		PrintCacheStats(workerID)
		latencyTracker.PrintStats()

		os.Exit(0)

	}()

	maxRetries := config.MaxRetries
	retryCount := 0

	//Main processing loop
	for {
		result, err := rdb.BRPop(ctx, time.Duration(config.WorkerTimeout)*time.Second, "url_queue").Result()
		if err != nil {
			if errors.Is(err, redis.Nil) {
				continue
			}

			log.Printf("[%s] âŒ Redis error: %v\n", workerID, err)
			retryCount++

			if retryCount >= maxRetries {
				log.Printf("[%s] âš ï¸  Max retries reached. Exiting.\n", workerID)
				os.Exit(1)
			}

			// Exponential backoff
			backoff := time.Duration(retryCount) * time.Second
			log.Printf("[%s] ğŸ”„ Retrying in %v...", workerID, backoff)
			time.Sleep(backoff)
			continue
		}

		retryCount = 0

		url := result[1]

		rdb.Incr(ctx, "processing")

		urlResult := checkURL(url, workerID, rdb)

		flusher.Add(ctx, urlResult)

		if urlResult.Error == "" {
			rdb.Incr(ctx, "success")
		} else {
			rdb.Incr(ctx, "error")
		}
		rdb.Decr(ctx, "processing")

		atomic.AddInt64(&processedCount, 1)

		if atomic.LoadInt64(&processedCount)%100 == 0 {
			log.Printf("[%s] ğŸ“ˆ Processed %d URLs", workerID, atomic.LoadInt64(&processedCount))
		}

		if atomic.LoadInt64(&processedCount)%500 == 0 {
			PrintCacheStats(workerID)
			latencyTracker.PrintStats()
		}
	}
}

func checkURL(url string, workerID string, rdb *redis.Client) URLResult {
	start := time.Now()
	result := cacheManager.Get(ctx, url, func(u string) URLResult {
		fetchStart := time.Now()
		res := URLResult{
			URL:       u,
			WorkerID:  workerID,
			CheckedAt: fetchStart,
		}

		resp, err := httpClient.Get(u)
		if err != nil {
			res.Error = err.Error()
			res.Duration = time.Since(fetchStart).Milliseconds()
			return res
		}
		defer resp.Body.Close()

		res.Status = resp.StatusCode
		res.Duration = time.Since(fetchStart).Milliseconds()

		if resp.StatusCode != 200 {
			res.Error = fmt.Sprintf("[%s] HTTP %d", workerID, resp.StatusCode)
		}

		return res
	})

	latency := time.Since(start)
	latencyTracker.Record(latency)

	return result
}

func PrintCacheStats(workerID string) {
	l1, l2, origin := cacheManager.GetStats()

	total := l1 + l2 + origin
	if total == 0 {
		return
	}

	l1Pct := (float64(l1) / float64(total)) * 100
	l2Pct := (float64(l2) / float64(total)) * 100
	originPct := (float64(origin) / float64(total)) * 100

	log.Printf("\n"+
		"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"+
		"[%s] ğŸ“Š CACHE STATS (Total: %d)\n"+
		"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"+
		"L1 hits:    %5d (%5.1f%%)  â† ~1Âµs latency\n"+
		"L2 hits:    %5d (%5.1f%%)  â† ~1ms latency\n"+
		"Origin:     %5d (%5.1f%%)  â† ~100ms latency\n"+
		"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"+
		"Cache efficiency: %.1f%% (L1+L2)\n"+
		"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
		workerID, total,
		l1, l1Pct,
		l2, l2Pct,
		origin, originPct,
		l1Pct+l2Pct,
	)
}
